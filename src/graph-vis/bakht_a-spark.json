{"paragraphs":[{"text":"import scala.util.parsing.json.JSON\n\ncase class Movie(\n    id: String,\n    title: String,\n    release_date: String,\n    genres: Seq[String],\n    adult: String,\n    popularity: String,\n    rating: String,\n    nbr_votes: String,\n    budget: String,\n    revenue: String,\n    duration: String,\n    url: String,\n    reviews: Option[Seq[String]],\n    popularity_from_reviews: Option[String]\n)\n\ndef parseJSON(s: String): Map[String, Any] = JSON.parseFull(s).get.asInstanceOf[Map[String, Any]]\n\ndef parseMovie(s : String): Option[Movie] = {\n    val json = parseJSON(s)\n    Some(Movie(\n        json(\"id\").toString,\n        json(\"title\").toString,\n        json(\"release_date\").toString,\n        Seq(json(\"genres\").toString),\n        json(\"adult\").toString,\n        json(\"popularity\").toString,\n        json(\"rating\").toString,\n        json(\"nbr_votes\").toString,\n        json(\"budget\").toString,\n        json(\"revenue\").toString,\n        json(\"duration\").toString,\n        json(\"url\").toString,\n        Some(Seq(json(\"reviews\").toString)),\n        Some(json(\"popularity_from_reviews\").toString)))\n}\n\n\n","user":"anonymous","dateUpdated":"2017-07-10T10:10:49+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport scala.util.parsing.json.JSON\n\ndefined class Movie\n\nparseJSON: (s: String)Map[String,Any]\n\nparseMovie: (s: String)Option[Movie]\n"}]},"apps":[],"jobName":"paragraph_1499621653801_-2022833793","id":"20170709-193413_275003073","dateCreated":"2017-07-09T19:34:13+0200","dateStarted":"2017-07-10T10:10:49+0200","dateFinished":"2017-07-10T10:10:50+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1334"},{"text":"val hdfs_path = \"/home/bach/Documents/projects/hadoop/movie-analytics/src/hdfs_utils/HDFS/\"\n\nval movies_str = sc.textFile(hdfs_path + \"[0-9]*/part-[0-9]*\")\n\nval movies = movies_str.flatMap(parseMovie)\n\n// convert to DataFrame and create temporal table\nmovies.toDF().registerTempTable(\"movies\")","user":"anonymous","dateUpdated":"2017-07-10T10:23:48+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nhdfs_path: String = /home/bach/Documents/projects/hadoop/movie-analytics/src/hdfs_utils/HDFS/\n\nmovies_str: org.apache.spark.rdd.RDD[String] = /home/bach/Documents/projects/hadoop/movie-analytics/src/hdfs_utils/HDFS/[0-9]*/part-[0-9]* MapPartitionsRDD[25] at textFile at <console>:33\n\nmovies: org.apache.spark.rdd.RDD[Movie] = MapPartitionsRDD[26] at flatMap at <console>:41\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]},"apps":[],"jobName":"paragraph_1499626680487_1930860107","id":"20170709-205800_369947220","dateCreated":"2017-07-09T20:58:00+0200","dateStarted":"2017-07-10T10:23:48+0200","dateFinished":"2017-07-10T10:23:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1335"},{"text":"%sql \nselect popularity, budget\nfrom movies\norder by popularity, budget asc","user":"anonymous","dateUpdated":"2017-07-10T10:23:53+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.util.NoSuchElementException: None.get\n\tat scala.None$.get(Option.scala:347)\n\tat scala.None$.get(Option.scala:345)\n\tat $line195971108223.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.parseJSON(<console>:29)\n\tat $line195971108224.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.parseMovie(<console>:34)\n\tat $line195971108256.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply(<console>:41)\n\tat $line195971108256.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply(<console>:41)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30)\n\tat org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:628)\n\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1422)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1419)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1499627170357_1878622913","id":"20170709-210610_1639257673","dateCreated":"2017-07-09T21:06:10+0200","dateStarted":"2017-07-10T10:23:53+0200","dateFinished":"2017-07-10T10:23:54+0200","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:1336"},{"text":"%sql\n","user":"anonymous","dateUpdated":"2017-07-10T10:15:31+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1499674531108_1362561764","id":"20170710-101531_1991958473","dateCreated":"2017-07-10T10:15:31+0200","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:1337"}],"name":"bakht_a-spark","id":"2CMD31SAV","angularObjects":{"2CQ7NDYQA:shared_process":[],"2CP1MSTBQ:shared_process":[],"2CNR3QHNZ:shared_process":[],"2CKP6N8R8:shared_process":[],"2CMDU3JMY:shared_process":[],"2CQ9J2PQ9:shared_process":[],"2CQCSBG6N:shared_process":[],"2CM65UKGG:shared_process":[],"2CM6DSJ67:shared_process":[],"2CN4Y4DF3:shared_process":[],"2CPRXXQK7:shared_process":[],"2CMTGNQQU:shared_process":[],"2CNR5N1BJ:shared_process":[],"2CKHDNHGN:shared_process":[],"2CPUYVZ3Y:shared_process":[],"2CPEKEXGK:shared_process":[],"2CPUQ47AD:shared_process":[],"2CMJEB65P:shared_process":[],"2CNB42KUQ:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}